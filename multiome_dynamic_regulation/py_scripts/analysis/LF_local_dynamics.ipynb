{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import dictys\n",
    "from dictys.net import stat\n",
    "import joblib\n",
    "import pickle\n",
    "from scipy.stats import median_abs_deviation, hypergeom\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_custom import *\n",
    "from episodic_dynamics import *\n",
    "from pseudotime_curves import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "dictys_dynamic_object_path = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/dynamic.h5\"\n",
    "output_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/blimp1_ko/gc_98'\n",
    "latent_factor_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors'\n",
    "lf_blimp1_file = f\"{latent_factor_folder}/feature_list_Z5_PRDM1_KO.txt\"\n",
    "lf_irf4_file = f\"{latent_factor_folder}/feature_list_Z4_IRF4_KO.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_blimp1 = pd.read_csv(lf_blimp1_file, sep='\\t')['names'].tolist()\n",
    "lf_irf4 = pd.read_csv(lf_irf4_file, sep='\\t')['names'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdictys_dynamic_object_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictys_dynamic_object_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_factor_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_factor_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrajectory_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_slice_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_slice_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# last index is excluded\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlf_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlf_blimp1\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mrun_episode\u001b[0;34m(episode_idx, dictys_dynamic_object_path, output_folder, latent_factor_folder, trajectory_range, num_points, time_slice_start, time_slice_end, lf_genes, percentile)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_episode\u001b[39m(\n\u001b[1;32m      2\u001b[0m     episode_idx,\n\u001b[1;32m      3\u001b[0m     dictys_dynamic_object_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m ):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Load dictys object inside the process\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     dictys_dynamic_object \u001b[38;5;241m=\u001b[39m \u001b[43mdictys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictys_dynamic_object_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     epi \u001b[38;5;241m=\u001b[39m EpisodeDynamics(\n\u001b[1;32m     16\u001b[0m         dictys_dynamic_object\u001b[38;5;241m=\u001b[39mdictys_dynamic_object,\n\u001b[1;32m     17\u001b[0m         output_folder\u001b[38;5;241m=\u001b[39moutput_folder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         sparsity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     epi\u001b[38;5;241m.\u001b[39mcompute_expression_curves()\n",
      "File \u001b[0;32m/ocean/projects/cis240075p/asachan/.conda/envs/dictys/lib/python3.9/site-packages/dictys/net/__init__.py:224\u001b[0m, in \u001b[0;36mnetwork.from_file\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    222\u001b[0m \t\tv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_version_\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m==\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 224\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_file_0_1_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown network version \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m v])))\n",
      "File \u001b[0;32m/ocean/projects/cis240075p/asachan/.conda/envs/dictys/lib/python3.9/site-packages/dictys/net/__init__.py:184\u001b[0m, in \u001b[0;36mnetwork._from_file_0_1_0\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    183\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m xj \u001b[38;5;129;01min\u001b[39;00m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m][xi]:\n\u001b[0;32m--> 184\u001b[0m \t\tparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m][xi][xj]\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \t\t\u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m][xi][xj]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    186\u001b[0m \t\t\tparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m][xi][xj]\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m'\u001b[39m][xi][xj]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/ocean/projects/cis240075p/asachan/.conda/envs/dictys/lib/python3.9/site-packages/h5py/_hl/dataset.py:1063\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1063\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/ocean/projects/cis240075p/asachan/.conda/envs/dictys/lib/python3.9/site-packages/h5py/_hl/dataset.py:1024\u001b[0m, in \u001b[0;36mDataset.read_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     dest_sel \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mselect(dest\u001b[38;5;241m.\u001b[39mshape, dest_sel)\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mspace \u001b[38;5;129;01min\u001b[39;00m dest_sel\u001b[38;5;241m.\u001b[39mbroadcast(source_sel\u001b[38;5;241m.\u001b[39marray_shape):\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_episode(\n",
    "    episode_idx=4,\n",
    "    dictys_dynamic_object_path=dictys_dynamic_object_path,\n",
    "    output_folder=output_folder,\n",
    "    latent_factor_folder=latent_factor_folder,\n",
    "    trajectory_range=(1, 3),\n",
    "    num_points=40,\n",
    "    time_slice_start=15,\n",
    "    time_slice_end=20, # last index is excluded\n",
    "    lf_genes=lf_blimp1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-parallelized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dictys_dynamic_object = dictys.net.dynamic_network.from_file(dictys_dynamic_object_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lcpm chars for these genes\n",
    "lcpm_dcurve, dtime = compute_expression_regulation_curves(dictys_dynamic_object, start=1, stop=3, num=40, dist=0.001, mode=\"expression\")\n",
    "# remove genes with names starting with ZNF and ZBTB\n",
    "lcpm_dcurve = lcpm_dcurve[~lcpm_dcurve.index.str.startswith('ZNF') & ~lcpm_dcurve.index.str.startswith('ZBTB')]\n",
    "# get lcpm chars for these genes\n",
    "#lcpm_dcurve_gc, dtime_gc = compute_expression_regulation_curves(dictys_dynamic_object, start=0, stop=3, num=20, dist=0.001, mode=\"expression\")\n",
    "# slice the dcurve for the lf genes using gene names which are indices in pandas df\n",
    "display(lcpm_dcurve.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regulation dynamics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, fsmooth = dictys_dynamic_object.linspace(1,3,40,0.001)\n",
    "stat1_net = fsmooth(stat.net(dictys_dynamic_object)) #varname=w_in loads total effect network\n",
    "stat1_netbin = stat.fbinarize(stat1_net,sparsity=0.01)\n",
    "stat1_x=stat.pseudotime(dictys_dynamic_object,pts)\n",
    "dtime = pd.Series(stat1_x.compute(pts)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get episode specific GRN (transient state specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts is a dictys traj object\n",
    "dnetbin = stat1_netbin.compute(pts)\n",
    "dnetbin_episode = dnetbin[:, :, 0:5] #5 timepoints, excludes the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weighted network\n",
    "dnet = stat1_net.compute(pts)\n",
    "dnet_episode = dnet[:, :, 0:5]\n",
    "display(dnet_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter episodic GRN edges which are significantly non-zero across time points and are direction invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Get the tf and target names #####\n",
    "# Create reverse mapping: index -> gene_name\n",
    "ndict = dictys_dynamic_object.ndict\n",
    "index_to_gene = {idx: name for name, idx in ndict.items()}\n",
    "target_names = [index_to_gene[idx] for idx in range(dnetbin_episode.shape[1])]\n",
    "# Get TF_gene_indices from TFs_to_keep_indices using nids[0]\n",
    "tf_gene_indices = [dictys_dynamic_object.nids[0][tf_idx] for tf_idx in range(dnetbin_episode.shape[0])]\n",
    "tf_names = [index_to_gene[idx] for idx in tf_gene_indices]\n",
    "print(len(target_names))\n",
    "print(len(tf_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Create multi-index tuples (all combinations of TF-target pairs) ######\n",
    "index_tuples = [(tf, target) for tf in tf_names for target in target_names]\n",
    "multi_index = pd.MultiIndex.from_tuples(index_tuples, names=['TF', 'Target'])\n",
    "# Reshape the subnetworks array to 2D (pairs Ã— time points)\n",
    "n_tfs, n_targets, n_times = dnet_episode.shape\n",
    "reshaped_data = dnet_episode.reshape(-1, n_times)\n",
    "# Create DataFrame with multi-index\n",
    "episode_beta_dcurve = pd.DataFrame(\n",
    "    reshaped_data,\n",
    "    index=multi_index,\n",
    "    columns=[f'time_{i}' for i in range(n_times)]\n",
    ")\n",
    "# drop rows that are all 0\n",
    "episode_beta_dcurve = episode_beta_dcurve[episode_beta_dcurve.sum(axis=1) != 0]\n",
    "# the number of edges here remain the same between episodes, indicating that exact 0 are the edges that don't have atac-seq basis\n",
    "display(episode_beta_dcurve.head())\n",
    "display(episode_beta_dcurve.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Filtering the global episodic GRN for retaining significantly non-zero and direction invariant edges ######\n",
    "filtered_edges = filter_edges_by_significance_and_direction(\n",
    "    episode_beta_dcurve,\n",
    "    min_nonzero_timepoints=3,\n",
    "    alpha=0.05,\n",
    "    min_observations=3,\n",
    "    check_direction_invariance=True,  # Enable direction invariance check\n",
    "    n_processes=60,\n",
    "    chunk_size=8000,\n",
    "    save_intermediate=False,\n",
    "    intermediate_path=output_folder\n",
    ")\n",
    "    \n",
    "print(f\"\\nFinal shape: {filtered_edges.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load episode parquet file into pandas\n",
    "#filtered_edges = pd.read_parquet('/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/filtered_edges_significant_invariant_PB_ep4.parquet')\n",
    "# remove TFs starting with ZNF or ZBTB\n",
    "filtered_edges = filtered_edges[~filtered_edges.index.get_level_values(0).str.startswith('ZNF') & ~filtered_edges.index.get_level_values(0).str.startswith('ZBTB')]\n",
    "display(filtered_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop edges with p_value > 0.01\n",
    "filtered_edges_p001 = filtered_edges[filtered_edges['p_value'] < 0.001]\n",
    "display(filtered_edges_p001.head())\n",
    "display(filtered_edges_p001.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TF forces for the episode & State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CHANGE STATE HERE ######\n",
    "tf_lcpm_values = lcpm_dcurve.loc[filtered_edges_p001.index.get_level_values(0).unique()]\n",
    "display(tf_lcpm_values.shape)\n",
    "###### CHANGE EPISODE HERE ######\n",
    "tf_lcpm_episode = tf_lcpm_values.iloc[:, 15:20]\n",
    "\n",
    "# Adaptive column renaming to match beta curves\n",
    "beta_time_cols = [col for col in filtered_edges_p001.columns if col.startswith('time_')]\n",
    "n_time_cols = len(beta_time_cols)\n",
    "\n",
    "# Rename TF expression columns to match beta curves format\n",
    "tf_lcpm_episode.columns = beta_time_cols[:n_time_cols]\n",
    "display(tf_lcpm_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare beta curves (only time columns)\n",
    "beta_curves_for_force = filtered_edges_p001.drop('p_value', axis=1)\n",
    "\n",
    "print(\"Starting parallel force calculation...\")\n",
    "print(f\"Input beta curves shape: {beta_curves_for_force.shape}\")\n",
    "print(f\"TF expression shape: {tf_lcpm_episode.shape}\")\n",
    "\n",
    "# Calculate forces in parallel\n",
    "force_curves = calculate_force_curves_parallel(\n",
    "    beta_curves=beta_curves_for_force,\n",
    "    tf_expression=tf_lcpm_episode,\n",
    "    n_processes=20,  # Adjust based on your system\n",
    "    chunk_size=30000,  # Adjust based on available memory\n",
    "    epsilon=1e-10,\n",
    "    save_intermediate=False\n",
    ")\n",
    "\n",
    "print(f\"Force calculation completed!\")\n",
    "print(f\"Output shape: {force_curves.shape}\")\n",
    "# Display sample results\n",
    "display(force_curves.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the average force over the episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average force over the 5 time points\n",
    "avg_force = force_curves.mean(axis=1)\n",
    "print(f\"Average force shape: {avg_force.shape}\")\n",
    "# Convert to DataFrame with proper column name\n",
    "avg_force_df = avg_force.to_frame(name='avg_force')\n",
    "display(avg_force_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "fig, axes = plt.subplots(1, 1, figsize=(15, 6))\n",
    "\n",
    "# Separate positive and negative forces\n",
    "positive_forces = avg_force[avg_force > 0]\n",
    "negative_forces = avg_force[avg_force < 0]\n",
    "\n",
    "axes.hist([positive_forces, negative_forces], bins=50, alpha=0.7, \n",
    "              color=['red', 'blue'], label=['Positive Forces', 'Negative Forces'], edgecolor='black')\n",
    "axes.set_xlabel('Average Force')\n",
    "axes.set_ylabel('Number of Edges')\n",
    "axes.set_title('Distribution by Force Direction')\n",
    "axes.legend()\n",
    "axes.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if len(positive_forces) > 0:\n",
    "    pos_threshold = np.percentile(positive_forces, 98)\n",
    "    top_pos_edges = positive_forces[positive_forces >= pos_threshold]\n",
    "else:\n",
    "    top_pos_edges = pd.Series(dtype=avg_force.dtype)\n",
    "\n",
    "if len(negative_forces) > 0:\n",
    "    neg_threshold = np.percentile(negative_forces, 0.5)\n",
    "    top_neg_edges = negative_forces[negative_forces <= neg_threshold]\n",
    "else:\n",
    "    top_neg_edges = pd.Series(dtype=avg_force.dtype)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "episodic_grn_edges = pd.concat([top_pos_edges, top_neg_edges]).to_frame(name='avg_force')\n",
    "\n",
    "# Optionally, sort by force value (descending for positive, ascending for negative)\n",
    "episodic_grn_edges = episodic_grn_edges.sort_values(by='avg_force', ascending=False)\n",
    "\n",
    "# Display or use as needed\n",
    "print(episodic_grn_edges)\n",
    "print(f\"Number of positive edges: {len(top_pos_edges)}\")\n",
    "print(f\"Number of negative edges: {len(top_neg_edges)}\")\n",
    "print(f\"Total selected edges: {len(episodic_grn_edges)}\")\n",
    "# display the unique tf and target numbers\n",
    "display(len(episodic_grn_edges.index.get_level_values(0).unique()))\n",
    "display(len(episodic_grn_edges.index.get_level_values(1).unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the top k% of edges to build the episodic GRN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the TFs acting on LF genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LF files \n",
    "z11_file = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors/feature_list_Z11_GC_PB.txt'\n",
    "z3_file = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors/feature_list_Z3_GC_PB.txt'\n",
    "z_prdm1_ko = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/other_files/latent_factors/feature_list_Z5_PRDM1_KO.txt\"\n",
    "# load into a list of gene names \n",
    "z11 = pd.read_csv(z11_file, sep='\\t', header=0)\n",
    "z3 = pd.read_csv(z3_file, sep='\\t', header=0)\n",
    "z_prdm1_ko = pd.read_csv(z_prdm1_ko, sep='\\t', header=0)\n",
    "# remove HLA- genes\n",
    "z11 = z11[~z11['names'].str.contains('HLA-')]\n",
    "z3 = z3[~z3['names'].str.contains('HLA-')]\n",
    "z_prdm1_ko = z_prdm1_ko[~z_prdm1_ko['names'].str.contains('HLA-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gene names \n",
    "z11_genes = z11['names'].tolist()\n",
    "z3_genes = z3['names'].tolist()\n",
    "z_prdm1_ko_genes = z_prdm1_ko['names'].tolist()\n",
    "# create a list of all lf genes \n",
    "#lf_genes = list(set(z11_genes + z3_genes))\n",
    "lf_genes = list(set(z_prdm1_ko_genes))\n",
    "lf_in_object = check_if_gene_in_ndict(dictys_dynamic_object, lf_genes, return_index=True)\n",
    "print(f\"Found {len(lf_in_object['present'])} genes\")\n",
    "print(f\"Missing {len(lf_in_object['missing'])} genes\")\n",
    "print(\"Indices:\", lf_in_object['indices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the enrichment (over representation) of LF genes in TF regulons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a boolean column indicating if the target is a lf gene in the episodic grn df\n",
    "episodic_grn_edges['is_in_lf'] = episodic_grn_edges.index.get_level_values(1).isin(lf_genes)\n",
    "# get the number of genes in the episodic grn edges\n",
    "target_genes_in_episodic_grn = episodic_grn_edges.index.get_level_values(1).unique()\n",
    "display(\"Number of targets in episodic grn: \", len(target_genes_in_episodic_grn))\n",
    "# get the number of lf_genes in the episodic grn edges\n",
    "lf_in_episodic_grn = episodic_grn_edges[episodic_grn_edges['is_in_lf']]\n",
    "display(lf_in_episodic_grn.head())\n",
    "# get the unique LF genes active in the lf_in_episodic_grn df\n",
    "lf_genes_active_in_episode = lf_in_episodic_grn.index.get_level_values(1).unique()\n",
    "display(\"Number of LF genes active in episode: \", len(lf_genes_active_in_episode))\n",
    "tfs_acting_on_lf = lf_in_episodic_grn.index.get_level_values(0).unique()\n",
    "display(\"TFs acting on LF genes: \", tfs_acting_on_lf, len(tfs_acting_on_lf))\n",
    "# take the tfs in the lf_in_episodic_grn df and subset the episodic_grn_edges df to only include these tfs\n",
    "episodic_grn_edges_subset = episodic_grn_edges[episodic_grn_edges.index.get_level_values(0).isin(lf_in_episodic_grn.index.get_level_values(0))]\n",
    "display(episodic_grn_edges_subset.head())\n",
    "display(episodic_grn_edges_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodic_enrichment_df = calculate_tf_episodic_enrichment(episodic_grn_edges_subset, \n",
    "                                       len(lf_genes_active_in_episode), \n",
    "                                       len(target_genes_in_episodic_grn))\n",
    "# sort the episodic_enrichment_df_p005 by enrichment_score in descending order\n",
    "episodic_enrichment_df_sorted = episodic_enrichment_df.sort_values(by='enrichment_score', ascending=False)\n",
    "# filter the episodic_enrichment_df to only include tfs with a p_value < threshold\n",
    "episodic_enrichment_df_p005 = episodic_enrichment_df_sorted[episodic_enrichment_df_sorted['p_value'] < 0.05]\n",
    "display(episodic_enrichment_df_p005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the episodic_enrichment_df_p005_sorted df to a csv file\n",
    "episodic_enrichment_df_sorted.to_csv(os.path.join(output_folder, 'enrichment_ep1_blimp_ko.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dictys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
