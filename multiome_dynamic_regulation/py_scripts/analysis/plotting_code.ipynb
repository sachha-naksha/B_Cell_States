{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import math\n",
    "import ast\n",
    "from scipy.stats import median_abs_deviation, hypergeom, mannwhitneyu\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dictys\n",
    "from utils_custom import *\n",
    "from pseudotime_curves import *\n",
    "from episode_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths \n",
    "data_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output'\n",
    "output_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/figures'\n",
    "input_folder = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell state distributions per fate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dictys_dynamic_object = dictys.net.dynamic_network.from_file(os.path.join(data_folder, 'dynamic.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barcode</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACAGCCAAGCCACT-3</td>\n",
       "      <td>GC-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACAGCCAAGGTGCA-1</td>\n",
       "      <td>ActB-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACAGCCAAGTTATC-1</td>\n",
       "      <td>ActB-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACAGCCAATAGCCC-1</td>\n",
       "      <td>ActB-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACAGCCAGTTAGCC-1</td>\n",
       "      <td>ActB-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Barcode Cluster\n",
       "0  AAACAGCCAAGCCACT-3    GC-1\n",
       "1  AAACAGCCAAGGTGCA-1  ActB-2\n",
       "2  AAACAGCCAAGTTATC-1  ActB-1\n",
       "3  AAACAGCCAATAGCCC-1  ActB-1\n",
       "4  AAACAGCCAGTTAGCC-1  ActB-1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=28494, step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cell_labels_file = '/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/data/clusters.csv'\n",
    "cell_labels = pd.read_csv(cell_labels_file, header=0)\n",
    "display(cell_labels.head())\n",
    "display(cell_labels.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_assignment_matrix = dictys_dynamic_object.prop[\"sc\"][\"w\"]\n",
    "state_labels_in_window = {}\n",
    "for window_idx in range(cell_assignment_matrix.shape[0]):\n",
    "    indices_of_cells_present_in_window = np.where(\n",
    "        cell_assignment_matrix[window_idx] == 1\n",
    "        )[0] #these indices start from 0\n",
    "    state_labels_in_window[window_idx] = [\n",
    "        cell_labels.iloc[int(idx)] for idx in indices_of_cells_present_in_window\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the columns in PB_fate_window_indices\n",
    "df_plot = cell_count_per_window_df[PB_post_bifurcation_window_indices]\n",
    "#remove ActB-1 from the dataframe rows\n",
    "df_plot = df_plot.drop(index=['ActB-1', 'earlyActB'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create time bins\n",
    "n_bins = 8  # Adjust this number as needed\n",
    "x = [pseudotime_values_of_windows[i] for i in PB_post_bifurcation_window_indices]\n",
    "x_min, x_max = min(x), max(x)\n",
    "\n",
    "# Create bin edges\n",
    "bin_edges = np.linspace(x_min, x_max, n_bins + 1)\n",
    "bin_centers = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(n_bins)]\n",
    "\n",
    "# Initialize binned data and count time points per bin\n",
    "binned_data = {state: [0] * n_bins for state in df_plot.index}\n",
    "bin_counts = [0] * n_bins  # Track how many time points are in each bin\n",
    "\n",
    "# Aggregate data into bins\n",
    "for i, time_point in enumerate(x):\n",
    "    # Find which bin this time point belongs to\n",
    "    bin_idx = np.digitize(time_point, bin_edges) - 1\n",
    "    bin_idx = max(0, min(bin_idx, n_bins - 1))  # Ensure within bounds\n",
    "    \n",
    "    # Add counts for each cell state to the appropriate bin\n",
    "    for state in df_plot.index:\n",
    "        binned_data[state][bin_idx] += df_plot.loc[state].values[i]\n",
    "    \n",
    "    bin_counts[bin_idx] += 1\n",
    "\n",
    "# Average the counts within each bin (so each bin represents average composition)\n",
    "for state in df_plot.index:\n",
    "    for bin_idx in range(n_bins):\n",
    "        if bin_counts[bin_idx] > 0:\n",
    "            binned_data[state][bin_idx] = binned_data[state][bin_idx] / bin_counts[bin_idx]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.style.use('default')\n",
    "plt.grid(False)\n",
    "\n",
    "# Initialize bottom array for stacking\n",
    "bottom = [0] * n_bins\n",
    "\n",
    "# Plot each cell state as a layer in the stacked bar\n",
    "for state in df_plot.index:\n",
    "    y = binned_data[state]\n",
    "    plt.bar(range(n_bins), y,\n",
    "            label=state,\n",
    "            color=colors_cell_count[state],\n",
    "            bottom=bottom,\n",
    "            alpha=0.8)\n",
    "    \n",
    "    # Update bottom for next stack layer\n",
    "    bottom = [bottom[i] + y[i] for i in range(n_bins)]\n",
    "\n",
    "plt.xlabel('Binned windows (PB branch)', fontsize=14, fontweight='bold', labelpad=15)\n",
    "plt.ylabel('Average Cell Count', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(n_bins), [f\"Bin {i+1}\" for i in range(n_bins)], fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print bin info for verification\n",
    "print(\"Time points per bin:\", bin_counts)\n",
    "print(\"Total cells per bin:\", [sum(binned_data[state][i] for state in df_plot.index) for i in range(n_bins)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the day5_6 data for PB and GC windows\n",
    "pb_indices = PB_post_bifurcation_window_indices\n",
    "gc_indices = GC_post_bifurcation_window_indices\n",
    "\n",
    "pb_pseudotime = [pseudotime_values_of_windows[i] for i in pb_indices]\n",
    "gc_pseudotime = [pseudotime_values_of_windows[i] for i in gc_indices]\n",
    "\n",
    "pb_day5_6 = day_count_per_window_df.loc['day5_6', pb_indices]\n",
    "gc_day5_6 = day_count_per_window_df.loc['day5_6', gc_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot PB branch\n",
    "plt.plot(pb_pseudotime, pb_day5_6, label='PB branch cells', color='#BB3636', linewidth=2)\n",
    "plt.fill_between(pb_pseudotime, pb_day5_6, color='#BB3636', alpha=0.25)\n",
    "\n",
    "# Plot GC branch\n",
    "plt.plot(gc_pseudotime, gc_day5_6, label='GC branch cells', color='#008000', linewidth=2)\n",
    "plt.fill_between(gc_pseudotime, gc_day5_6, color='#008000', alpha=0.25)\n",
    "\n",
    "plt.xlabel('Pseudotime')\n",
    "plt.ylabel('Day 5 to 6 Cell Counts')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episodic enrichment plots\n",
    "### Direct effect enrichment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### State discriminative LFs \n",
    "# PB\n",
    "pb_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep1_pb.csv\"\n",
    "pb_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep2_pb.csv\"\n",
    "pb_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep3_pb.csv\"\n",
    "pb_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep4_pb.csv\"\n",
    "# GC\n",
    "gc_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep1_gc.csv\"\n",
    "gc_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep2_gc.csv\"\n",
    "gc_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep3_gc.csv\"\n",
    "gc_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/direct_effect_enrichment/enrichment_ep4_gc.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF perturbation LFs\n",
    "# irf4 model \n",
    "# GC\n",
    "gc_irf4_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_1.csv\"\n",
    "gc_irf4_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_2.csv\"\n",
    "gc_irf4_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_3.csv\"\n",
    "gc_irf4_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_4.csv\"\n",
    "gc_irf4_ep5 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_5.csv\"\n",
    "gc_irf4_ep6 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_6.csv\"\n",
    "gc_irf4_ep7 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_7.csv\"\n",
    "gc_irf4_ep8 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/irf4_ko/gc_98/enrichment_episode_8.csv\"\n",
    "\n",
    "# prdm1 model \n",
    "# GC\n",
    "gc_blimp1_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_1.csv\"\n",
    "gc_blimp1_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_2.csv\"\n",
    "gc_blimp1_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_3.csv\"\n",
    "gc_blimp1_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_4.csv\"\n",
    "gc_blimp1_ep5 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_5.csv\"\n",
    "gc_blimp1_ep6 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_6.csv\"\n",
    "gc_blimp1_ep7 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_7.csv\"\n",
    "gc_blimp1_ep8 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/multiome_1st_donor_UPMC_aggr/dictys_outs/actb1_added_v2/output/intermediate_tmp_files/prdm1_ko/gc_98/enrichment_episode_8.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ets1 sig LFs\n",
    "ets1_sig_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/sig_LFs/enrichment_episode_1.csv\"\n",
    "ets1_sig_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/sig_LFs/enrichment_episode_2.csv\"\n",
    "ets1_sig_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/sig_LFs/enrichment_episode_3.csv\"\n",
    "ets1_sig_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/sig_LFs/enrichment_episode_4.csv\"\n",
    "ets1_sig_ep5 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/sig_LFs/enrichment_episode_5.csv\"\n",
    "ets1_sig_ep6 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/sig_LFs/enrichment_episode_6.csv\"\n",
    "\n",
    "# ets1 all LFs\n",
    "ets1_all_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/all_lfs/enrichment_episode_1.csv\"\n",
    "ets1_all_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/all_lfs/enrichment_episode_2.csv\"\n",
    "ets1_all_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/all_lfs/enrichment_episode_3.csv\"\n",
    "ets1_all_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/all_lfs/enrichment_episode_4.csv\"\n",
    "ets1_all_ep5 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/all_lfs/enrichment_episode_5.csv\"\n",
    "ets1_all_ep6 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ets1/all_lfs/enrichment_episode_6.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ikzf1 sig LF model \n",
    "ikzf1_sig_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/sig_lfs/enrichment_episode_1.csv\"\n",
    "ikzf1_sig_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/sig_lfs/enrichment_episode_2.csv\"\n",
    "ikzf1_sig_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/sig_lfs/enrichment_episode_3.csv\"\n",
    "ikzf1_sig_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/sig_lfs/enrichment_episode_4.csv\"\n",
    "ikzf1_sig_ep5 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/sig_lfs/enrichment_episode_5.csv\"\n",
    "ikzf1_sig_ep6 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/sig_lfs/enrichment_episode_6.csv\"\n",
    "\n",
    "# ikzf1 all LF model \n",
    "ikzf1_all_ep1 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/all_lfs/enrichment_episode_1.csv\"\n",
    "ikzf1_all_ep2 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/all_lfs/enrichment_episode_2.csv\"\n",
    "ikzf1_all_ep3 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/all_lfs/enrichment_episode_3.csv\"\n",
    "ikzf1_all_ep4 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/all_lfs/enrichment_episode_4.csv\"\n",
    "ikzf1_all_ep5 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/all_lfs/enrichment_episode_5.csv\"\n",
    "ikzf1_all_ep6 = \"/ocean/projects/cis240075p/asachan/datasets/B_Cell/T_cell/outs/dictys/rbpj_ntc/output/ikzf1/all_lfs/enrichment_episode_6.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tf_episodic_enrichment_dotplot(\n",
    "    dfs,\n",
    "    episode_labels,\n",
    "    figsize=(12, 8),\n",
    "    min_dot_size=10,\n",
    "    max_dot_size=300,\n",
    "    p_value_threshold=0.05,\n",
    "    min_significance_threshold=None,\n",
    "    min_targets_in_lf=2,\n",
    "    min_targets_dwnstrm=2,\n",
    "    cmap_name=\"coolwarm\",\n",
    "    value_legend_title=\"ES\",\n",
    "    size_legend_title=\"P-val\",\n",
    "    sort_by_gene_similarity=False,\n",
    "    show_dendrogram=False,\n",
    "    dendrogram_ratio=0.2,\n",
    "    figure_title=None,\n",
    "    log_scale=False,\n",
    "    show_plot=True,\n",
    "    tf_order=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a dotplot for TF episodic enrichment where dot color represents enrichment score \n",
    "    and dot size represents p-value significance (smaller p-value = larger dot).\n",
    "    \n",
    "    TFs can be sorted in three ways (priority order):\n",
    "    1. Custom order (if tf_order is provided)\n",
    "    2. Gene similarity clustering (if sort_by_gene_similarity=True)\n",
    "    3. Alphabetical (default)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tf_order : list of str, optional\n",
    "        Custom order for TF rows. If provided, overrides other sorting methods.\n",
    "        TFs not in the list will be appended alphabetically at the end.\n",
    "        TFs in the list but not in the data will be ignored.\n",
    "    \"\"\"    \n",
    "    # 1. Input validation\n",
    "    required_cols = ['TF', 'p_value', 'enrichment_score', 'genes_in_lf', 'genes_dwnstrm']\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        if df is None or df.empty:\n",
    "            print(f\"Episode {i+1} dataframe is None or empty.\")\n",
    "            return None, None, None  # FIXED: Changed from return None, None\n",
    "        for col in required_cols:\n",
    "            if col not in df.columns:\n",
    "                print(f\"Episode {i+1} dataframe missing required column: {col}\")\n",
    "                return None, None, None  # FIXED: Changed from return None, None\n",
    "    \n",
    "    # 2. Helper function to parse genes_in_lf column\n",
    "    def parse_genes_in_lf(genes_str):\n",
    "        \"\"\"Parse the string representation of genes tuple.\"\"\"\n",
    "        try:\n",
    "            if pd.isna(genes_str) or genes_str == '' or genes_str == '()':\n",
    "                return set()\n",
    "            # Handle string representation of tuples\n",
    "            genes_tuple = ast.literal_eval(genes_str)\n",
    "            if isinstance(genes_tuple, tuple):\n",
    "                return set(genes_tuple)\n",
    "            elif isinstance(genes_tuple, str):\n",
    "                return {genes_tuple}\n",
    "            else:\n",
    "                return set()\n",
    "        except:\n",
    "            return set()\n",
    "                \n",
    "    # 3. Collect all TFs and their associated genes across all episodes\n",
    "    tf_genes_dict = {}  # TF -> set of genes across all episodes\n",
    "    tf_dwnstrm_genes_dict = {}  # TF -> set of downstream genes across all episodes\n",
    "    plot_data_list = []\n",
    "    \n",
    "    for i, (df, episode_label) in enumerate(zip(dfs, episode_labels)):\n",
    "        df_clean = df.dropna(subset=['TF', 'p_value', 'enrichment_score'])\n",
    "        \n",
    "        for _, row in df_clean.iterrows():\n",
    "            tf_name = row['TF']\n",
    "            genes_in_lf_set = parse_genes_in_lf(row.get('genes_in_lf', ''))\n",
    "            genes_dwnstrm_set = parse_genes_in_lf(row.get('genes_dwnstrm', ''))\n",
    "            \n",
    "            # Accumulate genes for each TF across episodes\n",
    "            if tf_name not in tf_genes_dict:\n",
    "                tf_genes_dict[tf_name] = set()\n",
    "                tf_dwnstrm_genes_dict[tf_name] = set()\n",
    "            tf_genes_dict[tf_name].update(genes_in_lf_set)\n",
    "            tf_dwnstrm_genes_dict[tf_name].update(genes_dwnstrm_set)\n",
    "            \n",
    "            plot_data_list.append({\n",
    "                'episode': episode_label,\n",
    "                'episode_idx': i,\n",
    "                'TF': tf_name,\n",
    "                'p_value': row['p_value'],\n",
    "                'enrichment_score': row['enrichment_score']\n",
    "            })\n",
    "    \n",
    "    if not plot_data_list:\n",
    "        print(\"No valid data found across all episodes.\")\n",
    "        return None, None, None  # FIXED, None  # FIXED: Changed from return None, None\n",
    "    \n",
    "    plot_data_df = pd.DataFrame(plot_data_list)\n",
    "    \n",
    "    # 4. Filter TFs based on gene count criteria (AND condition)\n",
    "    valid_tfs = set()\n",
    "    for tf_name in tf_genes_dict.keys():\n",
    "        lf_gene_count = len(tf_genes_dict[tf_name])\n",
    "        dwnstrm_gene_count = len(tf_dwnstrm_genes_dict[tf_name])\n",
    "        \n",
    "        if lf_gene_count >= min_targets_in_lf and dwnstrm_gene_count >= min_targets_dwnstrm:\n",
    "            valid_tfs.add(tf_name)\n",
    "    \n",
    "    if not valid_tfs:\n",
    "        print(f\"No TFs meet the criteria: >= {min_targets_in_lf} LF genes AND >= {min_targets_dwnstrm} downstream genes\")\n",
    "        return None, None, None  # FIXED, None  # FIXED: Changed from return None, None\n",
    "    \n",
    "    # Filter plot data and gene dictionaries to only include valid TFs\n",
    "    plot_data_df = plot_data_df[plot_data_df['TF'].isin(valid_tfs)]\n",
    "    tf_genes_dict = {tf: genes for tf, genes in tf_genes_dict.items() if tf in valid_tfs}\n",
    "    tf_dwnstrm_genes_dict = {tf: genes for tf, genes in tf_dwnstrm_genes_dict.items() if tf in valid_tfs}\n",
    "    \n",
    "    print(f\"Filtered to {len(valid_tfs)} TFs that meet gene count criteria\")\n",
    "    \n",
    "    # 5. Filter TFs based on significance threshold\n",
    "    if min_significance_threshold is not None:\n",
    "        # Find TFs that have at least one episode with p-value < min_significance_threshold\n",
    "        significant_tfs = set()\n",
    "        tf_min_pvalues = plot_data_df.groupby('TF')['p_value'].min()\n",
    "        significant_tfs = set(tf_min_pvalues[tf_min_pvalues < min_significance_threshold].index)\n",
    "        \n",
    "        if not significant_tfs:\n",
    "            print(f\"No TFs meet the minimum significance threshold of {min_significance_threshold}\")\n",
    "            return None, None, None  # FIXED, None  # FIXED: Changed from return None, None\n",
    "\n",
    "        # Filter the plot data to only include significant TFs\n",
    "        plot_data_df = plot_data_df[plot_data_df['TF'].isin(significant_tfs)]\n",
    "        \n",
    "        # Update tf_genes_dict to only include significant TFs\n",
    "        tf_genes_dict = {tf: genes for tf, genes in tf_genes_dict.items() if tf in significant_tfs}\n",
    "        \n",
    "        print(f\"Further filtered to {len(significant_tfs)} TFs that meet significance threshold < {min_significance_threshold}\")\n",
    "\n",
    "    # 6. Sort TFs based on specified method\n",
    "    # Priority: custom order > gene similarity > alphabetical\n",
    "    if tf_order is not None:\n",
    "        # Use custom order\n",
    "        available_tfs = set(tf_genes_dict.keys())\n",
    "        \n",
    "        # Filter custom order to only include TFs present in the data\n",
    "        all_tfs_sorted = [tf for tf in tf_order if tf in available_tfs]\n",
    "        \n",
    "        # Add any TFs not in custom order (alphabetically sorted)\n",
    "        remaining_tfs = sorted(available_tfs - set(all_tfs_sorted))\n",
    "        all_tfs_sorted.extend(remaining_tfs)\n",
    "        \n",
    "        linkage_matrix = None\n",
    "        original_tf_labels = None\n",
    "        \n",
    "        if remaining_tfs:\n",
    "            print(f\"Note: {len(remaining_tfs)} TFs not in custom order were added alphabetically: {remaining_tfs}\")\n",
    "            \n",
    "    elif sort_by_gene_similarity:\n",
    "        if show_dendrogram:\n",
    "            all_tfs_sorted, linkage_matrix, original_tf_labels = sort_tfs_by_gene_similarity(\n",
    "                tf_genes_dict, return_linkage=True)\n",
    "        else:\n",
    "            all_tfs_sorted = sort_tfs_by_gene_similarity(tf_genes_dict)\n",
    "            linkage_matrix = None\n",
    "            original_tf_labels = None\n",
    "    else:\n",
    "        all_tfs_sorted = sorted(tf_genes_dict.keys())\n",
    "        linkage_matrix = None\n",
    "        original_tf_labels = None\n",
    "    \n",
    "    # 7. Map p-values to dot sizes (updated using Scanpy-like logic)\n",
    "    def p_value_to_size(p_val):\n",
    "        if p_val > p_value_threshold:\n",
    "            return min_dot_size * 0.5  # Smaller dot for non-significant\n",
    "        # Scale significant p-values\n",
    "        min_p_cap = 1e-6  # Prevents -log10(0)\n",
    "        log_p = -np.log10(max(p_val, min_p_cap))\n",
    "        log_thresh = -np.log10(p_value_threshold)\n",
    "        log_min_cap = -np.log10(min_p_cap)\n",
    "        \n",
    "        if log_min_cap == log_thresh:\n",
    "            scaled_val = 1.0  # Avoid div-by-zero\n",
    "        else:\n",
    "            scaled_val = (log_p - log_thresh) / (log_min_cap - log_thresh)\n",
    "        \n",
    "        size = min_dot_size + (max_dot_size - min_dot_size) * min(scaled_val, 1.0)\n",
    "        return size\n",
    "\n",
    "    plot_data_df['dot_size'] = plot_data_df['p_value'].apply(p_value_to_size)\n",
    "\n",
    "    # apply log scale to enrichment score\n",
    "    if log_scale:\n",
    "        # add offset\n",
    "        min_enrichment = plot_data_df['enrichment_score'].min()\n",
    "        if min_enrichment <= 0:\n",
    "            offset = abs(min_enrichment) + 1e-6\n",
    "            plot_data_df['enrichment_score_log'] = np.log2(plot_data_df['enrichment_score'] + offset)\n",
    "            value_legend_title = f\"log2({value_legend_title} + {offset:.1e})\"\n",
    "        else:\n",
    "            plot_data_df['enrichment_score_log'] = np.log2(plot_data_df['enrichment_score'])\n",
    "            value_legend_title = f\"log2({value_legend_title})\"\n",
    "        \n",
    "        # Use log-transformed values for coloring\n",
    "        color_values = plot_data_df['enrichment_score_log']\n",
    "    else:\n",
    "        color_values = plot_data_df['enrichment_score']\n",
    "\n",
    "    # 8. Create coordinate mappings\n",
    "    episode_x_coords = {label: i for i, label in enumerate(episode_labels)}\n",
    "    tf_y_coords = {tf: i for i, tf in enumerate(all_tfs_sorted)}\n",
    "    \n",
    "    # 9. Create figure with subplots\n",
    "    if show_dendrogram and linkage_matrix is not None and sort_by_gene_similarity:\n",
    "        # Create figure with dendrogram and main plot\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Calculate subplot widths\n",
    "        dendro_width = dendrogram_ratio\n",
    "        main_width = 1 - dendrogram_ratio - 0.15  # Leave space for colorbar\n",
    "        \n",
    "        # Create subplots\n",
    "        ax_dendro = fig.add_subplot(1, 2, 1)\n",
    "        ax_main = fig.add_subplot(1, 2, 2)\n",
    "        \n",
    "        # Adjust subplot positions\n",
    "        dendro_left = 0.05\n",
    "        main_left = dendro_left + dendro_width + 0.02\n",
    "        \n",
    "        ax_dendro.set_position([dendro_left, 0.1, dendro_width, 0.8])\n",
    "        ax_main.set_position([main_left, 0.1, main_width, 0.8])\n",
    "\n",
    "        # Plot dendrogram\n",
    "        dendro_plot = dendrogram(\n",
    "            linkage_matrix, \n",
    "            ax=ax_dendro,\n",
    "            orientation='left',\n",
    "            labels=original_tf_labels,\n",
    "            leaf_font_size=8,\n",
    "            color_threshold=0.7*max(linkage_matrix[:,2])\n",
    "        )\n",
    "        ax_dendro.invert_yaxis()\n",
    "        ax_dendro.set_ylabel(\"TF Clustering\")\n",
    "        ax_dendro.set_xlabel(\"Distance\")\n",
    "        ax_dendro.spines['top'].set_visible(False)\n",
    "        ax_dendro.spines['right'].set_visible(False)\n",
    "        \n",
    "        # Remove x-axis labels for cleaner look\n",
    "        ax_dendro.tick_params(axis='y', which='both', left=False, labelleft=False)\n",
    "        \n",
    "    else:\n",
    "        # Standard single plot\n",
    "        fig, ax_main = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # 10. Create scatter plot\n",
    "    scatter = ax_main.scatter(\n",
    "        x=plot_data_df['episode'].map(episode_x_coords),\n",
    "        y=plot_data_df['TF'].map(tf_y_coords),\n",
    "        s=plot_data_df['dot_size'],\n",
    "        c=color_values,\n",
    "        cmap=cmap_name,\n",
    "        edgecolors='gray',\n",
    "        linewidths=0.5,\n",
    "        alpha=0.8\n",
    "    )\n",
    "    \n",
    "    # 11. Axis formatting\n",
    "    # X-axis (Episodes)\n",
    "    ax_main.set_xticks(list(episode_x_coords.values()))\n",
    "    ax_main.set_xticklabels(episode_labels, rotation=0, ha=\"center\")\n",
    "    # Add horizontal padding to main plot\n",
    "    x_pad = 0.5  # tweak this to get desired spacing\n",
    "    ax_main.set_xlim(-x_pad, len(episode_labels) - 1 + x_pad)\n",
    "\n",
    "    ax_main.set_xlabel(\"Episodes\", fontsize=12, fontweight='bold', labelpad=15)\n",
    "    \n",
    "    # Y-axis (TFs)\n",
    "    ax_main.set_yticks(list(tf_y_coords.values()))\n",
    "    ax_main.set_yticklabels(all_tfs_sorted)\n",
    "    ax_main.set_ylabel(\"TFs\", fontsize=12, fontweight='bold')\n",
    "    # 12. Size legend for P-values\n",
    "    # Create representative p-values for the legend\n",
    "    legend_p_values = [0.001, 0.01]\n",
    "    legend_dots = []\n",
    "    \n",
    "    for p_val in legend_p_values:\n",
    "        size_val = p_value_to_size(p_val)\n",
    "        if p_val > p_value_threshold:\n",
    "            label_text = f\"{p_value_threshold}\"\n",
    "        else:\n",
    "            label_text = f\"{p_val}\"\n",
    "        legend_dots.append(plt.scatter([], [], s=size_val, c='gray', label=label_text))\n",
    "    \n",
    "    # Position the size legend\n",
    "    if show_dendrogram and linkage_matrix is not None and sort_by_gene_similarity:\n",
    "        bbox_anchor = (1.25, 0.6)\n",
    "    else:\n",
    "        bbox_anchor = (1.18, 0.6)\n",
    "        \n",
    "    size_leg = ax_main.legend(\n",
    "        handles=legend_dots, \n",
    "        title=size_legend_title,\n",
    "        bbox_to_anchor=bbox_anchor, \n",
    "        loc='center left',\n",
    "        labelspacing=1.5, \n",
    "        borderpad=1, \n",
    "        frameon=True,\n",
    "        handletextpad=1.5,\n",
    "        scatterpoints=1\n",
    "    )\n",
    "    \n",
    "    # 13. Horizontal Colorbar for Enrichment Score (positioned below p-value legend)\n",
    "    if show_dendrogram and linkage_matrix is not None and sort_by_gene_similarity:\n",
    "        # Create axes for horizontal colorbar below the p-value legend\n",
    "        cbar_ax = fig.add_axes([0.85, 0.15, 0.3, 0.03])  # [left, bottom, width, height]\n",
    "    else:\n",
    "        # Create axes for horizontal colorbar below the p-value legend\n",
    "        cbar_ax = fig.add_axes([0.65, 0.4, 0.2, 0.02])  # [left, bottom, width, height]\n",
    "    \n",
    "    cbar = fig.colorbar(scatter, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar.set_label(value_legend_title, fontsize=10)\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "    # 14. Final formatting\n",
    "    sorting_method = \"gene similarity\" if sort_by_gene_similarity else \"alphabetical\" \n",
    "    ax_main.grid(True, linestyle='--', alpha=0.3, axis='both')\n",
    "    ax_main.tick_params(axis='both', which='major', pad=5)\n",
    "    \n",
    "    # Invert y-axis so first TF is at top\n",
    "    ax_main.invert_yaxis()\n",
    "    \n",
    "    # Add figure title if provided\n",
    "    if figure_title is not None:\n",
    "        fig.suptitle(figure_title, fontsize=14, fontweight='bold', y=0.95)\n",
    "\n",
    "    if show_plot:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return fig, plot_data_df, all_tfs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep1 = pd.read_csv(gc_ep1)\n",
    "df_ep2 = pd.read_csv(gc_ep2)\n",
    "df_ep3 = pd.read_csv(gc_ep3)\n",
    "df_ep4 = pd.read_csv(gc_ep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired TF order\n",
    "# custom_tf_order_prdm1 = ['BPTF', 'SP1', 'BATF3', 'RBPJ', 'IKZF2']\n",
    "# custom_tf_order_irf4 = ['MBD2', 'IKZF2', 'RBPJ', 'TCF12', 'BACH1', 'HMG20A']\n",
    "# custom_tf_order_ets1_sig = ['Hdac2', 'Nfkb1', 'Ets1', 'Sin3a', 'Max']\n",
    "# custom_tf_order_ikzf1_all = ['Ep300', 'E2f2', 'Klf6', 'Nfe2', 'Taf1', 'Nr4a2', 'Bhlhe40', 'Rad21', 'Klf2', 'Ctcf']\n",
    "# custom_tf_order_ets1_all = ['Myc', 'Nfe2', 'Ets1', 'Elf1', 'Srf', 'Max', 'E2f2', 'Bhlhe41', 'Sp4']\n",
    "# custom_tf_order_z11_pb = ['CREB3L2', 'MEF2C', 'TFEC', 'TEAD2', 'IRF8', 'IRF9']\n",
    "custom_tf_order_z11_gc = ['IKZF3', 'USF2', 'IRF7', 'MEF2C', 'CDC5L', 'POU2F1']\n",
    "\n",
    "# Use it in the plot\n",
    "fig, plot_data, plotted_tfs = plot_tf_episodic_enrichment_dotplot(\n",
    "    dfs=[df_ep1, df_ep2, df_ep3, df_ep4],\n",
    "    episode_labels=['ActB3/4', '.', '..', 'lateGC'],\n",
    "    figsize=(4.5, 4), #breadth by length\n",
    "    p_value_threshold=0.009,\n",
    "    min_significance_threshold=0.009, \n",
    "    min_targets_in_lf=2,\n",
    "    min_targets_dwnstrm=2,\n",
    "    cmap_name=\"Greens\",\n",
    "    tf_order=custom_tf_order_z11_gc,\n",
    "    figure_title=None,\n",
    "    log_scale=True\n",
    ")\n",
    "# save the plot\n",
    "fig.savefig(os.path.join(output_folder, \"z11_ee_gc.pdf\"), dpi=300)\n",
    "#0.0015 for PB, 0.009 for GC in the gc_pb lf\n",
    "#0.0015 for prdm1 ko, 0.012 for irf4 ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromatin level TF activity over pseudotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dictys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
